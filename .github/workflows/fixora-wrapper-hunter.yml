name: Fixora Wrapper Hunter

on:
  repository_dispatch:
    types: [fixora-wrapper-hunt]
  workflow_dispatch:
    inputs:
      scan_id:
        description: 'Fixora scan ID for tracking'
        required: true
      target_branch:
        description: 'Branch to analyze'
        required: true
        default: 'main'

jobs:
  wrapper-hunt:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.client_payload.target_branch || github.event.inputs.target_branch }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run Wrapper Hunter
        run: |
          cat > /tmp/wrapper_hunter.py << 'HUNTER_SCRIPT'
          #!/usr/bin/env python3
          """
          Fixora Wrapper Hunter - Dependency Mapping & Custom Wrapper Detection
          Analyzes a project to find all dependencies, default modules,
          and custom wrapper functions that call external libraries.
          """
          import ast
          import os
          import re
          import json
          import sys

          # ============ PHASE 0: KNOWN DEFAULT / STDLIB MODULES ============

          PYTHON_STDLIB = {
              "abc", "aifc", "argparse", "array", "ast", "asynchat", "asyncio",
              "asyncore", "atexit", "audioop", "base64", "bdb", "binascii",
              "binhex", "bisect", "builtins", "bz2", "calendar", "cgi", "cgitb",
              "chunk", "cmath", "cmd", "code", "codecs", "codeop", "collections",
              "colorsys", "compileall", "concurrent", "configparser", "contextlib",
              "contextvars", "copy", "copyreg", "cProfile", "crypt", "csv",
              "ctypes", "curses", "dataclasses", "datetime", "dbm", "decimal",
              "difflib", "dis", "distutils", "doctest", "email", "encodings",
              "enum", "errno", "faulthandler", "fcntl", "filecmp", "fileinput",
              "fnmatch", "fractions", "ftplib", "functools", "gc", "getopt",
              "getpass", "gettext", "glob", "grp", "gzip", "hashlib", "heapq",
              "hmac", "html", "http", "idlelib", "imaplib", "imghdr", "imp",
              "importlib", "inspect", "io", "ipaddress", "itertools", "json",
              "keyword", "lib2to3", "linecache", "locale", "logging", "lzma",
              "mailbox", "mailcap", "marshal", "math", "mimetypes", "mmap",
              "modulefinder", "multiprocessing", "netrc", "nis", "nntplib",
              "numbers", "operator", "optparse", "os", "ossaudiodev",
              "pathlib", "pdb", "pickle", "pickletools", "pipes", "pkgutil",
              "platform", "plistlib", "poplib", "posix", "posixpath", "pprint",
              "profile", "pstats", "pty", "pwd", "py_compile", "pyclbr",
              "pydoc", "queue", "quopri", "random", "re", "readline", "reprlib",
              "resource", "rlcompleter", "runpy", "sched", "secrets", "select",
              "selectors", "shelve", "shlex", "shutil", "signal", "site",
              "smtpd", "smtplib", "sndhdr", "socket", "socketserver", "sqlite3",
              "ssl", "stat", "statistics", "string", "stringprep", "struct",
              "subprocess", "sunau", "symtable", "sys", "sysconfig", "syslog",
              "tabnanny", "tarfile", "telnetlib", "tempfile", "termios", "test",
              "textwrap", "threading", "time", "timeit", "tkinter", "token",
              "tokenize", "trace", "traceback", "tracemalloc", "tty", "turtle",
              "turtledemo", "types", "typing", "unicodedata", "unittest",
              "urllib", "uu", "uuid", "venv", "warnings", "wave", "weakref",
              "webbrowser", "winreg", "winsound", "wsgiref", "xdrlib", "xml",
              "xmlrpc", "zipapp", "zipfile", "zipimport", "zlib",
              "_thread", "__future__",
          }

          NODE_BUILTINS = {
              "assert", "buffer", "child_process", "cluster", "console",
              "constants", "crypto", "dgram", "dns", "domain", "events",
              "fs", "http", "https", "module", "net", "os", "path",
              "perf_hooks", "process", "punycode", "querystring", "readline",
              "repl", "stream", "string_decoder", "timers", "tls", "tty",
              "url", "util", "v8", "vm", "worker_threads", "zlib",
              "react", "react-dom", "react/jsx-runtime",
          }

          IGNORE_DIRS = {
              "node_modules", "venv", ".venv", "env", ".env", ".git",
              "__pycache__", "build", "dist", ".next", ".cache",
              "coverage", ".tox", "egg-info", ".eggs", "site-packages",
              ".github", ".vscode",
          }

          # ============ PHASE 1: DEPENDENCY MAPPING ============

          def parse_requirements_txt(repo_root):
              """Parse requirements.txt and return set of package names"""
              deps = set()
              req_path = os.path.join(repo_root, "requirements.txt")
              if not os.path.isfile(req_path):
                  return deps
              with open(req_path, "r", errors="ignore") as f:
                  for line in f:
                      line = line.strip()
                      if not line or line.startswith("#") or line.startswith("-"):
                          continue
                      # Strip version specifiers
                      pkg = re.split(r"[><=!~;@\[]", line)[0].strip()
                      if pkg:
                          deps.add(pkg.lower().replace("-", "_"))
              return deps

          def parse_package_json(repo_root):
              """Parse package.json and return set of dependency names"""
              deps = set()
              pj_path = os.path.join(repo_root, "package.json")
              if not os.path.isfile(pj_path):
                  return deps
              try:
                  with open(pj_path, "r", errors="ignore") as f:
                      data = json.load(f)
                  for key in ("dependencies", "devDependencies", "peerDependencies"):
                      if key in data and isinstance(data[key], dict):
                          deps.update(data[key].keys())
              except Exception:
                  pass
              return deps

          # ============ PHASE 2: IMPORT EXTRACTION ============

          def extract_python_imports(filepath):
              """Use AST to extract all imports from a Python file"""
              imports = []
              try:
                  with open(filepath, "r", errors="ignore") as f:
                      source = f.read()
                  tree = ast.parse(source, filename=filepath)
              except (SyntaxError, UnicodeDecodeError, ValueError):
                  return imports

              for node in ast.walk(tree):
                  if isinstance(node, ast.Import):
                      for alias in node.names:
                          imports.append({
                              "module": alias.name,
                              "names": [alias.asname or alias.name],
                              "type": "import"
                          })
                  elif isinstance(node, ast.ImportFrom):
                      module = node.module or ""
                      names = [a.name for a in node.names]
                      imports.append({
                          "module": module,
                          "names": names,
                          "type": "from_import"
                      })
              return imports

          # Regex patterns for JS/TS imports
          RE_ES6_IMPORT = re.compile(
              r"""import\s+(?:"""
              r"""(?P<default>[\w$]+)"""              # default import
              r"""|\{\s*(?P<named>[^}]+)\s*\}"""   # named imports
              r"""|(?P<def2>[\w$]+)\s*,\s*\{\s*(?P<named2>[^}]+)\s*\}"""  # default + named
              r"""|\*\s+as\s+(?P<star>[\w$]+)"""   # namespace import
              r""")\s+from\s+['"](?P<source>[^'"]+)['"]""",
              re.MULTILINE,
          )
          RE_REQUIRE = re.compile(
              r"""(?:const|let|var)\s+(?:"""
              r"""(?P<name>[\w$]+)"""
              r"""|\{\s*(?P<destructured>[^}]+)\s*\}"""
              r""")\s*=\s*require\(['"](?P<source>[^'"]+)['"]\)""",
              re.MULTILINE,
          )

          def extract_js_imports(filepath):
              """Use regex to extract imports from JS/TS files"""
              imports = []
              try:
                  with open(filepath, "r", errors="ignore") as f:
                      source = f.read()
              except Exception:
                  return imports

              for m in RE_ES6_IMPORT.finditer(source):
                  src = m.group("source")
                  names = []
                  if m.group("default"):
                      names.append(m.group("default"))
                  if m.group("named"):
                      names.extend([n.strip().split(" as ")[0].strip() for n in m.group("named").split(",")])
                  if m.group("def2"):
                      names.append(m.group("def2"))
                  if m.group("named2"):
                      names.extend([n.strip().split(" as ")[0].strip() for n in m.group("named2").split(",")])
                  if m.group("star"):
                      names.append(m.group("star"))
                  imports.append({"module": src, "names": names, "type": "es6_import"})

              for m in RE_REQUIRE.finditer(source):
                  src = m.group("source")
                  names = []
                  if m.group("name"):
                      names.append(m.group("name"))
                  if m.group("destructured"):
                      names.extend([n.strip().split(":")[0].strip() for n in m.group("destructured").split(",")])
                  imports.append({"module": src, "names": names, "type": "require"})

              return imports

          # ============ PHASE 3: WRAPPER FUNCTION DETECTION (Python) ============

          def classify_import(module_name, user_deps, stdlib_set):
              """Classify a module as user-installed, stdlib, or local"""
              top = module_name.split(".")[0].lower().replace("-", "_")
              if top in {d.lower().replace("-", "_") for d in user_deps}:
                  return "user_installed"
              if top in stdlib_set:
                  return "stdlib"
              return "local"

          def classify_js_import(module_name, user_deps, builtins):
              """Classify a JS module"""
              # Relative imports are local
              if module_name.startswith(".") or module_name.startswith("/"):
                  return "local"
              # Scoped packages: @scope/pkg -> check @scope/pkg
              top = module_name.split("/")[0] if not module_name.startswith("@") else "/".join(module_name.split("/")[:2])
              if top in user_deps:
                  return "user_installed"
              if top in builtins:
                  return "stdlib"
              return "user_installed"  # assume npm package if not builtin

          def extract_python_wrappers(filepath, user_deps):
              """
              Use AST to find functions that call any module listed in user_deps.
              Returns list of wrapper function dicts with source code.
              """
              wrappers = []
              try:
                  with open(filepath, "r", errors="ignore") as f:
                      source = f.read()
                  tree = ast.parse(source, filename=filepath)
                  lines = source.splitlines()
              except (SyntaxError, UnicodeDecodeError, ValueError):
                  return wrappers

              # Collect imported names that map to user-installed deps
              imported_names = set()
              for node in ast.walk(tree):
                  if isinstance(node, ast.Import):
                      for alias in node.names:
                          top = alias.name.split(".")[0].lower().replace("-", "_")
                          if top in {d.lower().replace("-", "_") for d in user_deps}:
                              imported_names.add(alias.asname or alias.name)
                  elif isinstance(node, ast.ImportFrom):
                      module = (node.module or "").split(".")[0].lower().replace("-", "_")
                      if module in {d.lower().replace("-", "_") for d in user_deps}:
                          for alias in node.names:
                              imported_names.add(alias.name)

              if not imported_names:
                  return wrappers

              # Find function definitions that call any imported name
              for node in ast.walk(tree):
                  if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                      calls_dep = set()
                      for child in ast.walk(node):
                          if isinstance(child, ast.Call):
                              call_name = _get_call_name(child)
                              if call_name:
                                  # Check if the call references an imported dep name
                                  root_name = call_name.split(".")[0]
                                  if root_name in imported_names:
                                      calls_dep.add(call_name)
                      if calls_dep:
                          # Extract full function source
                          start = node.lineno - 1
                          end = node.end_lineno if hasattr(node, "end_lineno") and node.end_lineno else start + 1
                          func_source = "\n".join(lines[start:end])
                          wrappers.append({
                              "function_name": node.name,
                              "calls": list(calls_dep),
                              "line_start": node.lineno,
                              "line_end": end,
                              "source_code": func_source,
                              "file": filepath
                          })
              return wrappers

          def _get_call_name(call_node):
              """Extract the full dotted name from a Call node"""
              func = call_node.func
              if isinstance(func, ast.Name):
                  return func.id
              elif isinstance(func, ast.Attribute):
                  parts = []
                  node = func
                  while isinstance(node, ast.Attribute):
                      parts.append(node.attr)
                      node = node.value
                  if isinstance(node, ast.Name):
                      parts.append(node.id)
                  return ".".join(reversed(parts))
              return None

          def extract_js_wrappers(filepath, user_deps):
              """
              Simple heuristic: find exported functions that use imported dep names.
              Uses regex since full JS AST is heavy.
              """
              wrappers = []
              try:
                  with open(filepath, "r", errors="ignore") as f:
                      source = f.read()
                      lines = source.splitlines()
              except Exception:
                  return wrappers

              # Gather imported names tied to user_deps
              imported_names = set()
              for m in RE_ES6_IMPORT.finditer(source):
                  src = m.group("source")
                  if src.startswith(".") or src.startswith("/"):
                      continue
                  top = src.split("/")[0] if not src.startswith("@") else "/".join(src.split("/")[:2])
                  if top in user_deps:
                      if m.group("default"):
                          imported_names.add(m.group("default"))
                      if m.group("named"):
                          for n in m.group("named").split(","):
                              imported_names.add(n.strip().split(" as ")[-1].strip())
                      if m.group("def2"):
                          imported_names.add(m.group("def2"))
                      if m.group("named2"):
                          for n in m.group("named2").split(","):
                              imported_names.add(n.strip().split(" as ")[-1].strip())

              for m in RE_REQUIRE.finditer(source):
                  src = m.group("source")
                  if src.startswith(".") or src.startswith("/"):
                      continue
                  top = src.split("/")[0] if not src.startswith("@") else "/".join(src.split("/")[:2])
                  if top in user_deps:
                      if m.group("name"):
                          imported_names.add(m.group("name"))
                      if m.group("destructured"):
                          for n in m.group("destructured").split(","):
                              imported_names.add(n.strip().split(":")[0].strip())

              if not imported_names:
                  return wrappers

              # Find function declarations that reference those names
              func_pattern = re.compile(
                  r"(?:^|\n)"
                  r"(?:export\s+)?(?:async\s+)?function\s+(\w+)\s*\([^)]*\)\s*\{",
                  re.MULTILINE,
              )
              arrow_pattern = re.compile(
                  r"(?:^|\n)"
                  r"(?:export\s+)?(?:const|let|var)\s+(\w+)\s*=\s*(?:async\s+)?(?:\([^)]*\)|\w+)\s*=>",
                  re.MULTILINE,
              )

              for pattern in [func_pattern, arrow_pattern]:
                  for m in pattern.finditer(source):
                      func_name = m.group(1)
                      start_pos = m.start()
                      start_line = source[:start_pos].count("\n")

                      # Find matching closing brace (simple brace counting)
                      brace_pos = source.find("{", m.end() - 1)
                      if brace_pos == -1:
                          # Arrow function without braces - take single line
                          end_line = start_line
                          func_body = lines[start_line] if start_line < len(lines) else ""
                      else:
                          depth = 0
                          end_pos = brace_pos
                          for i in range(brace_pos, len(source)):
                              if source[i] == "{":
                                  depth += 1
                              elif source[i] == "}":
                                  depth -= 1
                                  if depth == 0:
                                      end_pos = i
                                      break
                          end_line = source[:end_pos + 1].count("\n")
                          func_body = "\n".join(lines[start_line:end_line + 1])

                      # Check if function body references any imported dep names
                      found_calls = set()
                      for name in imported_names:
                          if name in func_body:
                              found_calls.add(name)

                      if found_calls:
                          wrappers.append({
                              "function_name": func_name,
                              "calls": list(found_calls),
                              "line_start": start_line + 1,
                              "line_end": end_line + 1,
                              "source_code": func_body,
                              "file": filepath
                          })

              return wrappers

          # ============ MAIN RUNNER ============

          def run_wrapper_hunter(repo_root="."):
              result = {
                  "python": None,
                  "react": None,
              }

              # Check what exists
              has_python = os.path.isfile(os.path.join(repo_root, "requirements.txt"))
              has_react = os.path.isfile(os.path.join(repo_root, "package.json"))

              # --- PYTHON ---
              if has_python:
                  py_user_deps = parse_requirements_txt(repo_root)
                  py_section = {
                      "packages": {
                          "user_installed": sorted(py_user_deps),
                          "stdlib": sorted(PYTHON_STDLIB),
                      },
                      "file_analysis": [],
                      "wrapper_functions": [],
                  }

                  for dirpath, dirnames, filenames in os.walk(repo_root):
                      dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]
                      for fn in filenames:
                          if not fn.endswith(".py"):
                              continue
                          fp = os.path.join(dirpath, fn)
                          rel = os.path.relpath(fp, repo_root)
                          imports = extract_python_imports(fp)
                          if not imports:
                              continue

                          classified = []
                          for imp in imports:
                              cat = classify_import(imp["module"], py_user_deps, PYTHON_STDLIB)
                              classified.append({**imp, "classification": cat})

                          py_section["file_analysis"].append({
                              "file": rel,
                              "imports": classified,
                          })

                          wrappers = extract_python_wrappers(fp, py_user_deps)
                          for w in wrappers:
                              w["file"] = rel
                              py_section["wrapper_functions"].append(w)

                  result["python"] = py_section

              # --- REACT / JS ---
              if has_react:
                  js_user_deps = parse_package_json(repo_root)
                  js_section = {
                      "packages": {
                          "user_installed": sorted(js_user_deps),
                          "builtin": sorted(NODE_BUILTINS),
                      },
                      "file_analysis": [],
                      "wrapper_functions": [],
                  }

                  for dirpath, dirnames, filenames in os.walk(repo_root):
                      dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]
                      for fn in filenames:
                          if not any(fn.endswith(ext) for ext in (".js", ".jsx", ".ts", ".tsx")):
                              continue
                          fp = os.path.join(dirpath, fn)
                          rel = os.path.relpath(fp, repo_root)
                          imports = extract_js_imports(fp)
                          if not imports:
                              continue

                          classified = []
                          for imp in imports:
                              cat = classify_js_import(imp["module"], js_user_deps, NODE_BUILTINS)
                              classified.append({**imp, "classification": cat})

                          js_section["file_analysis"].append({
                              "file": rel,
                              "imports": classified,
                          })

                          wrappers = extract_js_wrappers(fp, js_user_deps)
                          for w in wrappers:
                              w["file"] = rel
                              js_section["wrapper_functions"].append(w)

                  result["react"] = js_section

              # Remove null sections
              result = {k: v for k, v in result.items() if v is not None}
              return result

          if __name__ == "__main__":
              output = run_wrapper_hunter(".")
              with open("wrapper-hunter-results.json", "w") as f:
                  json.dump(output, f, indent=2)
              print(json.dumps(output, indent=2))
          HUNTER_SCRIPT
          python3 /tmp/wrapper_hunter.py

      - name: Send Wrapper Hunter Results to Fixora
        run: |
          SCAN_ID="${{ github.event.client_payload.scan_id || github.event.inputs.scan_id }}"
          
          if [ -f wrapper-hunter-results.json ]; then
            echo "Sending wrapper hunter results to Fixora backend..."
            
            # Build payload
            jq -n --arg scan_id "$SCAN_ID" --arg repo "${{ github.repository }}" \
              --slurpfile results wrapper-hunter-results.json \
              '{scan_id: $scan_id, repository: $repo, wrapper_data: $results[0]}' > wh-payload.json
            
            MAX_RETRIES=3
            RETRY_COUNT=0
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              echo "Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES..."
              if curl -X POST "${{ secrets.FIXORA_API_URL }}/api/scan/webhook/wrapper-results" \
                -H "Content-Type: application/json" \
                -H "X-Fixora-Token: ${{ secrets.FIXORA_API_TOKEN }}" \
                -d @wh-payload.json \
                --max-time 30 \
                --retry 2 \
                --retry-delay 5; then
                echo "\n✅ Wrapper hunter results sent successfully"
                exit 0
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                echo "⚠️  Attempt $RETRY_COUNT failed. Retrying..."
                sleep 5
              fi
            done
            
            echo "❌ Failed to send wrapper hunter results after $MAX_RETRIES attempts"
            exit 1
          else
            echo "⚠️  No wrapper hunter results file found"
          fi

      - name: Upload Wrapper Hunter Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: wrapper-hunter-results
          path: wrapper-hunter-results.json
          retention-days: 7
